{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of AlphaFold2_with_ManualTemplates.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "be3e224c70094eab9282889aed846dfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_959a63e5881f4e87ba4dff27835ad1c4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_616fb16d0cc74228b8a69234d17cb01a",
              "IPY_MODEL_0955ecb3b4774e73b6db1c02c81cac4f",
              "IPY_MODEL_a6d613eed1bc4bb5b4839048661c0a57"
            ]
          }
        },
        "959a63e5881f4e87ba4dff27835ad1c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "616fb16d0cc74228b8a69234d17cb01a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_13a5de0e3ec848c2b1be19e9a4497a8c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "COMPLETE: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e8b3b3ca0b824c25995e53b70d32a382"
          }
        },
        "0955ecb3b4774e73b6db1c02c81cac4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c72dcec4187b43b588a787ee08bcb831",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 150,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 150,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5fc8306d06564a12bb2e89d0e81f92b5"
          }
        },
        "a6d613eed1bc4bb5b4839048661c0a57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b402cb9c0378463f8983dd1a750f61d3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 150/150 [elapsed: 00:02 remaining: 00:00]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_28e30264566e47b5bd861940ac4c4325"
          }
        },
        "13a5de0e3ec848c2b1be19e9a4497a8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e8b3b3ca0b824c25995e53b70d32a382": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c72dcec4187b43b588a787ee08bcb831": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5fc8306d06564a12bb2e89d0e81f92b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b402cb9c0378463f8983dd1a750f61d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "28e30264566e47b5bd861940ac4c4325": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cschlick/colabfolds/blob/main/Copy_of_AlphaFold2_with_ManualTemplates.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4yBrceuFbf3"
      },
      "source": [
        "#ColabFold: AlphaFold2 w/ MMseqs2\n",
        "-----------------\n",
        "- <b><font color='green'>21Aug2021: The MSA/Templates issues should now be resolved! Please report any errors you see.</font></b>\n",
        "-----------------\n",
        "<img src=\"https://raw.githubusercontent.com/sokrypton/ColabFold/main/.github/ColabFold_Marv_Logo_Small.png\" height=\"256\" align=\"right\" style=\"height:256px\">\n",
        "\n",
        "Easy to use AlphaFold2 [(Jumper et al. 2021)](https://www.nature.com/articles/s41586-021-03819-2) protein structure prediction using multiple sequence alignments generated through an MMseqs2 API. For details, refer to our manuscript:\n",
        "\n",
        "[Mirdita M, Ovchinnikov S, Steinegger M. ColabFold - Making protein folding accessible to all.\n",
        "*bioRxiv*, 2021](https://www.biorxiv.org/content/10.1101/2021.08.15.456425v1) \n",
        "\n",
        "- This notebook provides basic functionality, for more advanced options (such as modeling heterocomplexes, increasing recycles, sampling, etc.) see our [advanced notebook](https://colab.research.google.com/github/sokrypton/ColabFold/blob/main/beta/AlphaFold2_advanced.ipynb).\n",
        "- This notebook replaces the homology detection of AlphaFold2 with MMseqs2. For a comparision against the [Deepmind Colab](https://colab.research.google.com/github/deepmind/alphafold/blob/main/notebooks/AlphaFold.ipynb) and the full [AlphaFold2](https://github.com/deepmind/alphafold) system read our [preprint](https://www.biorxiv.org/content/10.1101/2021.08.15.456425v1). \n",
        "\n",
        "\n",
        "<strong>For more details, see <a href=\"#Instructions\">bottom</a> of the notebook and checkout the [ColabFold GitHub](https://github.com/sokrypton/ColabFold). </strong>\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOblAo-xetgx",
        "cellView": "form"
      },
      "source": [
        "#@title Input protein sequence, then hit `Runtime` -> `Run all`\n",
        "from google.colab import files\n",
        "import os\n",
        "import os.path\n",
        "import re\n",
        "import hashlib\n",
        "\n",
        "def add_hash(x,y):\n",
        "  return x+\"_\"+hashlib.sha1(y.encode()).hexdigest()[:5]\n",
        "\n",
        "query_sequence = 'EVQLVESGGGLVNPGGSLRLSCAASGFTFSDYTIHWVRQAPGKGLEWVSSISSSSNYIYYADSVKGRFTISRDNAKNSLS LQMNSLRAEDTAVYYCARDGNAYKWLLAENVRFDYWGQGTLVTVSS' #@param {type:\"string\"}\n",
        "# remove whitespaces\n",
        "query_sequence = \"\".join(query_sequence.split())\n",
        "query_sequence = re.sub(r'[^a-zA-Z]','', query_sequence).upper()\n",
        "\n",
        "jobname = 'manual_template' #@param {type:\"string\"}\n",
        "# remove whitespaces\n",
        "jobname = \"\".join(jobname.split())\n",
        "jobname = re.sub(r'\\W+', '', jobname)\n",
        "jobname = add_hash(jobname, query_sequence)\n",
        "\n",
        "\n",
        "with open(f\"{jobname}.fasta\", \"w\") as text_file:\n",
        "    text_file.write(\">1\\n%s\" % query_sequence)\n",
        "\n",
        "# number of models to use\n",
        "#@markdown ---\n",
        "#@markdown ### Advanced settings\n",
        "msa_mode = \"MMseqs2 (UniRef+Environmental)\" #@param [\"MMseqs2 (UniRef+Environmental)\", \"MMseqs2 (UniRef only)\",\"single_sequence\",\"custom\"]\n",
        "num_models = 5 #@param [1,2,3,4,5] {type:\"raw\"}\n",
        "use_msa = True if msa_mode.startswith(\"MMseqs2\") else False\n",
        "use_env = True if msa_mode == \"MMseqs2 (UniRef+Environmental)\" else False\n",
        "use_custom_msa = True if msa_mode == \"custom\" else False\n",
        "use_amber = False #@param {type:\"boolean\"}\n",
        "use_templates = True #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "#@markdown ### Experimental options\n",
        "homooligomer = 1 #@param [1,2,3,4,5,6,7,8] {type:\"raw\"}\n",
        "save_to_google_drive = False #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "#@markdown Don't forget to hit `Runtime` -> `Run all` after updating the form.\n",
        "\n",
        "\n",
        "if homooligomer > 1:\n",
        "  if use_amber:\n",
        "    print(\"amber disabled: amber is not currently supported for homooligomers\")\n",
        "    use_amber = False\n",
        "  if use_templates:\n",
        "    print(\"templates disabled: templates are not currently supported for homooligomers\")\n",
        "    use_templates = False\n",
        "\n",
        "with open(f\"{jobname}.log\", \"w\") as text_file:\n",
        "    text_file.write(\"num_models=%s\\n\" % num_models)\n",
        "    text_file.write(\"use_amber=%s\\n\" % use_amber)\n",
        "    text_file.write(\"use_msa=%s\\n\" % use_msa)\n",
        "    text_file.write(\"msa_mode=%s\\n\" % msa_mode)\n",
        "    text_file.write(\"use_templates=%s\\n\" % use_templates)\n",
        "    text_file.write(\"homooligomer=%s\\n\" % homooligomer)\n",
        "\n",
        "# decide which a3m to use\n",
        "if use_msa:\n",
        "  a3m_file = f\"{jobname}.a3m\"\n",
        "elif use_custom_msa:\n",
        "  a3m_file = f\"{jobname}.custom.a3m\"\n",
        "  if not os.path.isfile(a3m_file):\n",
        "    custom_msa_dict = files.upload()\n",
        "    custom_msa = list(custom_msa_dict.keys())[0]\n",
        "    header = 0\n",
        "    import fileinput\n",
        "    for line in fileinput.FileInput(custom_msa,inplace=1):\n",
        "      if line.startswith(\">\"):\n",
        "         header = header + 1 \n",
        "      if line.startswith(\"#\"):\n",
        "        continue\n",
        "      if line.rstrip() == False:\n",
        "        continue\n",
        "      if line.startswith(\">\") == False and header == 1:\n",
        "         query_sequence = line.rstrip() \n",
        "      print(line, end='')\n",
        "\n",
        "    os.rename(custom_msa, a3m_file)\n",
        "    print(f\"moving {custom_msa} to {a3m_file}\")\n",
        "else:\n",
        "  a3m_file = f\"{jobname}.single_sequence.a3m\"\n",
        "  with open(a3m_file, \"w\") as text_file:\n",
        "    text_file.write(\">1\\n%s\" % query_sequence)\n",
        "\n",
        "if save_to_google_drive == True:\n",
        "  from pydrive.drive import GoogleDrive\n",
        "  from pydrive.auth import GoogleAuth\n",
        "  from google.colab import auth\n",
        "  from oauth2client.client import GoogleCredentials\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  print(\"You are logged into Google Drive and are good to go!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iccGdbe_Pmt9",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceb96c0a-3eb0-49d4-d9ec-79428cd14478"
      },
      "source": [
        "#@title Install dependencies\n",
        "%%bash -s $use_amber $use_msa $use_templates\n",
        "\n",
        "USE_AMBER=$1\n",
        "USE_MSA=$2\n",
        "USE_TEMPLATES=$3\n",
        "\n",
        "if [ ! -f AF2_READY ]; then\n",
        "  # install dependencies\n",
        "  pip -q install biopython dm-haiku ml-collections py3Dmol\n",
        "  wget -qnc https://raw.githubusercontent.com/sokrypton/ColabFold/main/beta/colabfold.py\n",
        "\n",
        "  # download model\n",
        "  if [ ! -d \"alphafold/\" ]; then\n",
        "    git clone https://github.com/deepmind/alphafold.git --quiet\n",
        "    (cd alphafold; git checkout 0bab1bf84d9d887aba5cfb6d09af1e8c3ecbc408 --quiet)\n",
        "    mv alphafold alphafold_\n",
        "    mv alphafold_/alphafold .\n",
        "    # remove \"END\" from PDBs, otherwise biopython complains\n",
        "    sed -i \"s/pdb_lines.append('END')//\" /content/alphafold/common/protein.py\n",
        "    sed -i \"s/pdb_lines.append('ENDMDL')//\" /content/alphafold/common/protein.py\n",
        "  fi\n",
        "\n",
        "  # download model params (~1 min)\n",
        "  if [ ! -d \"params/\" ]; then\n",
        "    mkdir params\n",
        "    curl -fsSL https://storage.googleapis.com/alphafold/alphafold_params_2021-07-14.tar \\\n",
        "    | tar x -C params\n",
        "  fi\n",
        "  touch AF2_READY\n",
        "fi\n",
        "# download libraries for interfacing with MMseqs2 API\n",
        "if [ ${USE_MSA} == \"True\" ] || [ ${USE_TEMPLATES} == \"True\" ]; then\n",
        "  if [ ! -f MMSEQ2_READY ]; then\n",
        "    apt-get -qq -y update 2>&1 1>/dev/null\n",
        "    apt-get -qq -y install jq curl zlib1g gawk 2>&1 1>/dev/null\n",
        "    touch MMSEQ2_READY\n",
        "  fi\n",
        "fi\n",
        "# setup conda\n",
        "if [ ${USE_AMBER} == \"True\" ] || [ ${USE_TEMPLATES} == \"True\" ]; then\n",
        "  if [ ! -f CONDA_READY ]; then\n",
        "    wget -qnc https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "    bash Miniconda3-latest-Linux-x86_64.sh -bfp /usr/local 2>&1 1>/dev/null\n",
        "    rm Miniconda3-latest-Linux-x86_64.sh\n",
        "    touch CONDA_READY\n",
        "  fi\n",
        "fi\n",
        "# setup template search\n",
        "if [ ${USE_TEMPLATES} == \"True\" ] && [ ! -f HH_READY ]; then\n",
        "  conda install -y -q -c conda-forge -c bioconda kalign3=3.2.2 hhsuite=3.3.0 python=3.7 2>&1 1>/dev/null\n",
        "  touch HH_READY\n",
        "fi\n",
        "# setup openmm for amber refinement\n",
        "if [ ${USE_AMBER} == \"True\" ] && [ ! -f AMBER_READY ]; then\n",
        "  conda install -y -q -c conda-forge openmm=7.5.1 python=3.7 pdbfixer 2>&1 1>/dev/null\n",
        "  (cd /usr/local/lib/python3.7/site-packages; patch -s -p0 < /content/alphafold_/docker/openmm.patch)\n",
        "  wget -qnc https://git.scicore.unibas.ch/schwede/openstructure/-/raw/7102c63615b64735c4941278d92b554ec94415f8/modules/mol/alg/src/stereo_chemical_props.txt\n",
        "  mv stereo_chemical_props.txt alphafold/common/\n",
        "  touch AMBER_READY\n",
        "fi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  0%|          | 0/38 [00:00<?, ?it/s]\rExtracting : pyopenssl-20.0.1-pyhd3eb1b0_1.conda:   0%|          | 0/38 [00:00<?, ?it/s]\rExtracting : conda-package-handling-1.7.3-py39h27cfd23_1.conda:   3%|▎         | 1/38 [00:00<00:01, 19.34it/s]\rExtracting : libgcc-ng-9.3.0-h5101ec6_17.conda:   5%|▌         | 2/38 [00:00<00:02, 13.39it/s]                \rExtracting : libgcc-ng-9.3.0-h5101ec6_17.conda:   8%|▊         | 3/38 [00:00<00:01, 20.05it/s]\rExtracting : setuptools-52.0.0-py39h06a4308_0.conda:   8%|▊         | 3/38 [00:00<00:01, 20.05it/s]\rExtracting : pip-21.1.3-py39h06a4308_0.conda:  11%|█         | 4/38 [00:00<00:01, 20.05it/s]       \rExtracting : pip-21.1.3-py39h06a4308_0.conda:  13%|█▎        | 5/38 [00:00<00:01, 16.80it/s]\rExtracting : ld_impl_linux-64-2.35.1-h7274673_9.conda:  13%|█▎        | 5/38 [00:00<00:01, 16.80it/s]\rExtracting : libstdcxx-ng-9.3.0-hd4cf53a_17.conda:  16%|█▌        | 6/38 [00:00<00:01, 16.80it/s]    \rExtracting : chardet-4.0.0-py39h06a4308_1003.conda:  18%|█▊        | 7/38 [00:00<00:01, 16.80it/s]\rExtracting : sqlite-3.36.0-hc218d9a_0.conda:  21%|██        | 8/38 [00:00<00:01, 16.80it/s]       \rExtracting : sqlite-3.36.0-hc218d9a_0.conda:  24%|██▎       | 9/38 [00:00<00:01, 15.04it/s]\rExtracting : readline-8.1-h27cfd23_0.conda:  24%|██▎       | 9/38 [00:00<00:01, 15.04it/s] \rExtracting : pysocks-1.7.1-py39h06a4308_0.conda:  26%|██▋       | 10/38 [00:00<00:01, 15.04it/s]\rExtracting : tzdata-2021a-h52ac0ba_0.conda:  29%|██▉       | 11/38 [00:00<00:01, 15.04it/s]     \rExtracting : ca-certificates-2021.7.5-h06a4308_1.conda:  32%|███▏      | 12/38 [00:00<00:01, 15.04it/s]\rExtracting : ruamel_yaml-0.15.100-py39h27cfd23_0.conda:  34%|███▍      | 13/38 [00:00<00:01, 15.04it/s]\rExtracting : brotlipy-0.7.0-py39h27cfd23_1003.conda:  37%|███▋      | 14/38 [00:00<00:01, 15.04it/s]   \rExtracting : xz-5.2.5-h7b6447c_0.conda:  39%|███▉      | 15/38 [00:00<00:01, 15.04it/s]             \rExtracting : yaml-0.2.5-h7b6447c_0.conda:  42%|████▏     | 16/38 [00:00<00:01, 15.04it/s]\rExtracting : cffi-1.14.6-py39h400218f_0.conda:  45%|████▍     | 17/38 [00:00<00:01, 15.04it/s]\rExtracting : tk-8.6.10-hbc83047_0.conda:  47%|████▋     | 18/38 [00:00<00:01, 15.04it/s]      \rExtracting : requests-2.25.1-pyhd3eb1b0_0.conda:  50%|█████     | 19/38 [00:00<00:01, 15.04it/s]\rExtracting : wheel-0.36.2-pyhd3eb1b0_0.conda:  53%|█████▎    | 20/38 [00:00<00:01, 15.04it/s]   \rExtracting : wheel-0.36.2-pyhd3eb1b0_0.conda:  55%|█████▌    | 21/38 [00:00<00:00, 19.16it/s]\rExtracting : ncurses-6.2-he6710b0_1.conda:  55%|█████▌    | 21/38 [00:00<00:00, 19.16it/s]   \rExtracting : openssl-1.1.1k-h27cfd23_0.conda:  58%|█████▊    | 22/38 [00:01<00:00, 19.16it/s]\rExtracting : pycparser-2.20-py_2.conda:  61%|██████    | 23/38 [00:01<00:00, 19.16it/s]      \rExtracting : pycparser-2.20-py_2.conda:  63%|██████▎   | 24/38 [00:01<00:00, 16.50it/s]\rExtracting : pycosat-0.6.3-py39h27cfd23_0.conda:  63%|██████▎   | 24/38 [00:01<00:00, 16.50it/s]\rExtracting : libgomp-9.3.0-h5101ec6_17.conda:  66%|██████▌   | 25/38 [00:01<00:00, 16.50it/s]   \rExtracting : tqdm-4.61.2-pyhd3eb1b0_1.conda:  68%|██████▊   | 26/38 [00:01<00:00, 16.50it/s] \rExtracting : certifi-2021.5.30-py39h06a4308_0.conda:  71%|███████   | 27/38 [00:01<00:00, 16.50it/s]\rExtracting : six-1.16.0-pyhd3eb1b0_0.conda:  74%|███████▎  | 28/38 [00:01<00:00, 16.50it/s]         \rExtracting : _libgcc_mutex-0.1-main.conda:  76%|███████▋  | 29/38 [00:01<00:00, 16.50it/s] \rExtracting : _libgcc_mutex-0.1-main.conda:  79%|███████▉  | 30/38 [00:01<00:00, 20.75it/s]\rExtracting : zlib-1.2.11-h7b6447c_3.conda:  79%|███████▉  | 30/38 [00:01<00:00, 20.75it/s]\rExtracting : urllib3-1.26.6-pyhd3eb1b0_1.conda:  82%|████████▏ | 31/38 [00:01<00:00, 20.75it/s]\rExtracting : libffi-3.3-he6710b0_2.conda:  84%|████████▍ | 32/38 [00:01<00:00, 20.75it/s]      \rExtracting : cryptography-3.4.7-py39hd23ed53_0.conda:  87%|████████▋ | 33/38 [00:01<00:00, 20.75it/s]\rExtracting : _openmp_mutex-4.5-1_gnu.tar.bz2:  89%|████████▉ | 34/38 [00:01<00:00, 20.75it/s]        \rExtracting : conda-4.10.3-py39h06a4308_0.tar.bz2:  92%|█████████▏| 35/38 [00:01<00:00, 20.75it/s]\rExtracting : conda-4.10.3-py39h06a4308_0.tar.bz2:  95%|█████████▍| 36/38 [00:01<00:00, 15.15it/s]\rExtracting : python-3.9.5-h12debd9_4.tar.bz2:  95%|█████████▍| 36/38 [00:04<00:00, 15.15it/s]    \rExtracting : idna-2.10-pyhd3eb1b0_0.tar.bz2:  97%|█████████▋| 37/38 [00:04<00:00, 15.15it/s] \r                                                                                            \r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "jFNCnjI9_DUG"
      },
      "source": [
        "#@title Import libraries\n",
        "# setup the model\n",
        "if \"model\" not in dir():\n",
        "\n",
        "  # hiding warning messages\n",
        "  import warnings\n",
        "  from absl import logging\n",
        "  import os\n",
        "  import tensorflow as tf\n",
        "  warnings.filterwarnings('ignore')\n",
        "  logging.set_verbosity(\"error\")\n",
        "  os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "  tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "  import sys\n",
        "  import numpy as np\n",
        "  import pickle\n",
        "  from alphafold.common import protein\n",
        "  from alphafold.data import pipeline\n",
        "  from alphafold.data import templates\n",
        "  from alphafold.model import data\n",
        "  from alphafold.model import config\n",
        "  from alphafold.model import model\n",
        "  from alphafold.data.tools import hhsearch\n",
        "  import colabfold as cf\n",
        "\n",
        "  # plotting libraries\n",
        "  import py3Dmol\n",
        "  import matplotlib.pyplot as plt\n",
        "  import ipywidgets\n",
        "  from ipywidgets import interact, fixed, GridspecLayout, Output\n",
        "\n",
        "\n",
        "if use_amber and \"relax\" not in dir():\n",
        "  sys.path.insert(0, '/usr/local/lib/python3.7/site-packages/')\n",
        "  from alphafold.relax import relax\n",
        "\n",
        "def mk_mock_template(query_sequence):\n",
        "  # since alphafold's model requires a template input\n",
        "  # we create a blank example w/ zero input, confidence -1\n",
        "  ln = len(query_sequence)\n",
        "  output_templates_sequence = \"-\"*ln\n",
        "  output_confidence_scores = np.full(ln,-1)\n",
        "  templates_all_atom_positions = np.zeros((ln, templates.residue_constants.atom_type_num, 3))\n",
        "  templates_all_atom_masks = np.zeros((ln, templates.residue_constants.atom_type_num))\n",
        "  templates_aatype = templates.residue_constants.sequence_to_onehot(output_templates_sequence,\n",
        "                                                                    templates.residue_constants.HHBLITS_AA_TO_ID)\n",
        "  template_features = {'template_all_atom_positions': templates_all_atom_positions[None],\n",
        "                       'template_all_atom_masks': templates_all_atom_masks[None],\n",
        "                       'template_sequence': [f'none'.encode()],\n",
        "                       'template_aatype': np.array(templates_aatype)[None],\n",
        "                       'template_confidence_scores': output_confidence_scores[None],\n",
        "                       'template_domain_names': [f'none'.encode()],\n",
        "                       'template_release_date': [f'none'.encode()]}\n",
        "  return template_features\n",
        "\n",
        "def mk_template(a3m_lines, template_paths):\n",
        "  template_featurizer = templates.TemplateHitFeaturizer(\n",
        "      mmcif_dir=template_paths,\n",
        "      max_template_date=\"2100-01-01\",\n",
        "      max_hits=20,\n",
        "      kalign_binary_path=\"kalign\",\n",
        "      release_dates_path=None,\n",
        "      obsolete_pdbs_path=None)\n",
        "\n",
        "  hhsearch_pdb70_runner = hhsearch.HHSearch(binary_path=\"hhsearch\", databases=[f\"{template_paths}/pdb70\"])\n",
        "\n",
        "  hhsearch_result = hhsearch_pdb70_runner.query(a3m_lines)\n",
        "  hhsearch_hits = pipeline.parsers.parse_hhr(hhsearch_result)\n",
        "  templates_result = template_featurizer.get_templates(query_sequence=query_sequence,\n",
        "                                                       query_pdb_code=None,\n",
        "                                                       query_release_date=None,\n",
        "                                                       hits=hhsearch_hits)\n",
        "  return templates_result.features\n",
        "\n",
        "def set_bfactor(pdb_filename, bfac, idx_res, chains):\n",
        "  I = open(pdb_filename,\"r\").readlines()\n",
        "  O = open(pdb_filename,\"w\")\n",
        "  for line in I:\n",
        "    if line[0:6] == \"ATOM  \":\n",
        "      seq_id = int(line[22:26].strip()) - 1\n",
        "      seq_id = np.where(idx_res == seq_id)[0][0]\n",
        "      O.write(f\"{line[:21]}{chains[seq_id]}{line[22:60]}{bfac[seq_id]:6.2f}{line[66:]}\")\n",
        "  O.close()\n",
        "\n",
        "def predict_structure(prefix, feature_dict, Ls, model_params, use_model, do_relax=False, random_seed=0):  \n",
        "  \"\"\"Predicts structure using AlphaFold for the given sequence.\"\"\"\n",
        "\n",
        "  # Minkyung's code\n",
        "  # add big enough number to residue index to indicate chain breaks\n",
        "  idx_res = feature_dict['residue_index']\n",
        "  L_prev = 0\n",
        "  # Ls: number of residues in each chain\n",
        "  for L_i in Ls[:-1]:\n",
        "      idx_res[L_prev+L_i:] += 200\n",
        "      L_prev += L_i  \n",
        "  chains = list(\"\".join([ascii_uppercase[n]*L for n,L in enumerate(Ls)]))\n",
        "  feature_dict['residue_index'] = idx_res\n",
        "\n",
        "  # Run the models.\n",
        "  plddts,paes = [],[]\n",
        "  unrelaxed_pdb_lines = []\n",
        "  relaxed_pdb_lines = []\n",
        "\n",
        "  for model_name, params in model_params.items():\n",
        "    if model_name in use_model:\n",
        "      print(f\"running {model_name}\")\n",
        "      # swap params to avoid recompiling\n",
        "      # note: models 1,2 have diff number of params compared to models 3,4,5\n",
        "      if any(str(m) in model_name for m in [1,2]): model_runner = model_runner_1\n",
        "      if any(str(m) in model_name for m in [3,4,5]): model_runner = model_runner_3\n",
        "      model_runner.params = params\n",
        "      \n",
        "      processed_feature_dict = model_runner.process_features(feature_dict, random_seed=random_seed)\n",
        "      prediction_result = model_runner.predict(processed_feature_dict)\n",
        "      unrelaxed_protein = protein.from_prediction(processed_feature_dict,prediction_result)\n",
        "      unrelaxed_pdb_lines.append(protein.to_pdb(unrelaxed_protein))\n",
        "      plddts.append(prediction_result['plddt'])\n",
        "      paes.append(prediction_result['predicted_aligned_error'])\n",
        "\n",
        "      if do_relax:\n",
        "        # Relax the prediction.\n",
        "        amber_relaxer = relax.AmberRelaxation(max_iterations=0,tolerance=2.39,\n",
        "                                              stiffness=10.0,exclude_residues=[],\n",
        "                                              max_outer_iterations=20)      \n",
        "        relaxed_pdb_str, _, _ = amber_relaxer.process(prot=unrelaxed_protein)\n",
        "        relaxed_pdb_lines.append(relaxed_pdb_str)\n",
        "\n",
        "  # rerank models based on predicted lddt\n",
        "  lddt_rank = np.mean(plddts,-1).argsort()[::-1]\n",
        "  out = {}\n",
        "  print(\"reranking models based on avg. predicted lDDT\")\n",
        "  for n,r in enumerate(lddt_rank):\n",
        "    print(f\"model_{n+1} {np.mean(plddts[r])}\")\n",
        "\n",
        "    unrelaxed_pdb_path = f'{prefix}_unrelaxed_model_{n+1}.pdb'    \n",
        "    with open(unrelaxed_pdb_path, 'w') as f: f.write(unrelaxed_pdb_lines[r])\n",
        "    set_bfactor(unrelaxed_pdb_path, plddts[r], idx_res, chains)\n",
        "\n",
        "    if do_relax:\n",
        "      relaxed_pdb_path = f'{prefix}_relaxed_model_{n+1}.pdb'\n",
        "      with open(relaxed_pdb_path, 'w') as f: f.write(relaxed_pdb_lines[r])\n",
        "      set_bfactor(relaxed_pdb_path, plddts[r], idx_res, chains)\n",
        "\n",
        "    out[f\"model_{n+1}\"] = {\"plddt\":plddts[r], \"pae\":paes[r]}\n",
        "  return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sztQyz29DIC",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414,
          "referenced_widgets": [
            "be3e224c70094eab9282889aed846dfc",
            "959a63e5881f4e87ba4dff27835ad1c4",
            "616fb16d0cc74228b8a69234d17cb01a",
            "0955ecb3b4774e73b6db1c02c81cac4f",
            "a6d613eed1bc4bb5b4839048661c0a57",
            "13a5de0e3ec848c2b1be19e9a4497a8c",
            "e8b3b3ca0b824c25995e53b70d32a382",
            "c72dcec4187b43b588a787ee08bcb831",
            "5fc8306d06564a12bb2e89d0e81f92b5",
            "b402cb9c0378463f8983dd1a750f61d3",
            "28e30264566e47b5bd861940ac4c4325"
          ]
        },
        "outputId": "1a5bbdbd-6ba0-4fe7-a6c2-d6b54b931380"
      },
      "source": [
        "#@title Call MMseqs2 to get MSA/templates\n",
        "if use_templates:\n",
        "  a3m_lines, template_paths = cf.run_mmseqs2(query_sequence, jobname, use_env, use_templates=True)\n",
        "  if template_paths is None:\n",
        "    template_features = mk_mock_template(query_sequence * homooligomer)\n",
        "  else:\n",
        "    template_features = mk_template(a3m_lines, template_paths)\n",
        "elif use_msa:\n",
        "  a3m_lines = cf.run_mmseqs2(query_sequence, jobname, use_env)\n",
        "  template_features = mk_mock_template(query_sequence * homooligomer)\n",
        "else:\n",
        "  template_features = mk_mock_template(query_sequence * homooligomer)\n",
        "\n",
        "if use_msa:\n",
        "  with open(a3m_file, \"w\") as text_file:\n",
        "    text_file.write(a3m_lines)\n",
        "else:\n",
        "  a3m_lines = \"\".join(open(a3m_file,\"r\").read())\n",
        "\n",
        "# parse MSA\n",
        "msa, deletion_matrix = pipeline.parsers.parse_a3m(a3m_lines)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be3e224c70094eab9282889aed846dfc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/150 [elapsed: 00:00 remaining: ?]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "seq\tpdb\tcid\tevalue\n",
            "0\t6QD6_D\t0.355\t8.108E-43\n",
            "0\t6QD6_G\t0.355\t8.108E-43\n",
            "0\t5WTS_A\t0.320\t2.869E-42\n",
            "0\t4PFE_A\t0.282\t8.835E-37\n",
            "0\t4UT7_H\t0.272\t1.106E-35\n",
            "0\t5OVW_J\t0.273\t2.605E-34\n",
            "0\t5VM6_A\t0.263\t4.900E-34\n",
            "0\t6RUM_A\t0.297\t4.900E-34\n",
            "0\t4OB5_H\t0.273\t9.217E-34\n",
            "0\t3JBE_7\t0.307\t9.217E-34\n",
            "0\t4JVP_A\t0.282\t1.264E-33\n",
            "0\t5FOJ_A\t0.302\t1.734E-33\n",
            "0\t5U64_B\t0.258\t1.734E-33\n",
            "0\t5H30_I\t0.257\t2.378E-33\n",
            "0\t5VM4_B\t0.265\t3.261E-33\n",
            "0\t1Y18_F\t0.288\t3.261E-33\n",
            "0\t5X08_H\t0.279\t4.472E-33\n",
            "0\t1XIW_H\t0.253\t8.412E-33\n",
            "0\t6VLR_F\t0.269\t1.154E-32\n",
            "0\t4M62_H\t0.253\t1.154E-32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "cellView": "form",
        "id": "jTBwpd8LmY8Y",
        "outputId": "fe68a7bd-e24d-4a72-e112-a6ca2f2e6609"
      },
      "source": [
        "#@markdown ---\n",
        "#@markdown ### Optional: Supply templates manually\n",
        "#@markdown If selected, you will be prompted to upload model files to use as templates. \\\n",
        "supply_manual_templates = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown **Note:** Before having installed dependencies, you must have also previously selected\n",
        "#@markdown - use_templates\n",
        "\n",
        "#@markdown **Warning:** This is not part of the intended way to run AlphaFold, so care must be taken in supplying templates and interpreting results.\n",
        "#@markdown - Templates provided here will override any templates found by the original mechanisms (homology search)\n",
        "#@markdown - Templates are split into chains, aligned to the query with hhsearch, and passed to the AlphaFold template featurizer\n",
        "#@markdown - No QA occurs on the templates you provide. If they are really bad, they might be rejected by the template featurizer\n",
        "#@markdown - PDB files are not supported. If converting from PDB to CIF, it needs to be a good conversion that builds fields not built by many available tools. Try this one: https://mmcif.pdbj.org/converter/index.php?l=en\n",
        "import os\n",
        "from io import StringIO\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from contextlib import redirect_stderr, redirect_stdout\n",
        "from dataclasses import dataclass, replace\n",
        "\n",
        "from alphafold.data import mmcif_parsing\n",
        "from alphafold.data.templates import (_get_pdb_id_and_chain,\n",
        "                                      _process_single_hit,\n",
        "                                      _assess_hhsearch_hit,\n",
        "                                      _build_query_to_hit_index_mapping,\n",
        "                                      _extract_template_features,\n",
        "                                      SingleHitResult,\n",
        "                                      TEMPLATE_FEATURES)\n",
        "from Bio.Seq import Seq\n",
        "from Bio.SeqRecord import SeqRecord\n",
        "from Bio import SeqIO\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "def hh_process_seq(query_seq,template_seq,hhDB_dir,db_prefix=\"DB\"):\n",
        "  \"\"\"\n",
        "  This is a hack to get hhsuite output strings to pass on\n",
        "  to the AlphaFold template featurizer. \n",
        "  \n",
        "  Note: that in the case of multiple templates, this would be faster to build one database for\n",
        "  all the templates. Currently it builds a database with only one template at a time. Even \n",
        "  better would be to get an hhsuite alignment without using a database at all, just between\n",
        "  pairs of sequence files. However, I have not figured out how to do this.\n",
        "\n",
        "  Update: I think the hhsearch can be replaced completely, and we can just do a pairwise \n",
        "  alignment with biopython, or skip alignment if the seqs match. TODO\n",
        "  \"\"\"\n",
        "  # set up directory for hhsuite DB. Place one template fasta file to be the DB contents\n",
        "  if hhDB_dir.exists():\n",
        "    shutil.rmtree(hhDB_dir)\n",
        "  \n",
        "  msa_dir = Path(hhDB_dir,\"msa\")\n",
        "  msa_dir.mkdir(parents=True)\n",
        "  template_seq_path = Path(msa_dir,\"template.fasta\")\n",
        "  with template_seq_path.open(\"w\") as fh:\n",
        "    SeqIO.write([template_seq], fh, \"fasta\")\n",
        "\n",
        "  # make hhsuite DB\n",
        "  with redirect_stdout(StringIO()) as out:\n",
        "    os.chdir(msa_dir)\n",
        "    %shell ffindex_build -s ../DB_msa.ff{data,index} .\n",
        "    os.chdir(hhDB_dir)\n",
        "    %shell ffindex_apply DB_msa.ff{data,index}  -i DB_a3m.ffindex -d DB_a3m.ffdata  -- hhconsensus -M 50 -maxres 65535 -i stdin -oa3m stdout -v 0\n",
        "    %shell rm DB_msa.ff{data,index}\n",
        "    %shell ffindex_apply DB_a3m.ff{data,index} -i DB_hhm.ffindex -d DB_hhm.ffdata -- hhmake -i stdin -o stdout -v 0\n",
        "    %shell cstranslate -f -x 0.3 -c 4 -I a3m -i DB_a3m -o DB_cs219 \n",
        "    %shell sort -k3 -n -r DB_cs219.ffindex | cut -f1 > sorting.dat\n",
        "\n",
        "    %shell ffindex_order sorting.dat DB_hhm.ff{data,index} DB_hhm_ordered.ff{data,index}\n",
        "    %shell mv DB_hhm_ordered.ffindex DB_hhm.ffindex\n",
        "    %shell mv DB_hhm_ordered.ffdata DB_hhm.ffdata\n",
        "\n",
        "    %shell ffindex_order sorting.dat DB_a3m.ff{data,index} DB_a3m_ordered.ff{data,index}\n",
        "    %shell mv DB_a3m_ordered.ffindex DB_a3m.ffindex\n",
        "    %shell mv DB_a3m_ordered.ffdata DB_a3m.ffdata\n",
        "\n",
        "  # run hhsearch\n",
        "  hhsearch_runner = hhsearch.HHSearch(binary_path=\"hhsearch\", databases=[hhDB_dir.as_posix()+\"/\"+db_prefix])\n",
        "  with StringIO() as fh:\n",
        "    SeqIO.write([query_seq], fh, \"fasta\")\n",
        "    seq_fasta = fh.getvalue()\n",
        "  hhsearch_result = hhsearch_runner.query(seq_fasta)\n",
        "\n",
        "  # process hits\n",
        "  hhsearch_hits = pipeline.parsers.parse_hhr(hhsearch_result)\n",
        "  if len(hhsearch_hits) >0:\n",
        "    hit = hhsearch_hits[0]\n",
        "    hit = replace(hit,**{\"name\":template_seq.id})\n",
        "  else:\n",
        "    hit = None\n",
        "    print(\"ERROR: Rejected template: \",template_seq.id)\n",
        "  return hit\n",
        "\n",
        "\n",
        "os.chdir(\"/content/\")\n",
        "if not supply_manual_templates:\n",
        "  print(\"Not using manual templates.\")\n",
        "else:\n",
        "\n",
        "  parent_dir = Path(\"/content/manual_templates\")\n",
        "  cif_dir = Path(parent_dir,\"mmcif\")\n",
        "  fasta_dir = Path(parent_dir,\"fasta\")\n",
        "  hhDB_dir = Path(parent_dir,\"hhDB\")\n",
        "  msa_dir = Path(hhDB_dir,\"msa\")\n",
        "  all_dirs = [parent_dir,cif_dir,fasta_dir,hhDB_dir,msa_dir]\n",
        "  for d in all_dirs:\n",
        "    if d.exists():\n",
        "      shutil.rmtree(d)\n",
        "    d.mkdir(parents=True)\n",
        "  \n",
        "  with redirect_stdout(StringIO()) as out:\n",
        "    uploaded = files.upload()\n",
        "    for filename,contents in uploaded.items():\n",
        "      filepath = Path(cif_dir,filename)\n",
        "      with filepath.open(\"w\") as fh:\n",
        "        fh.write(contents.decode(\"UTF-8\"))\n",
        "\n",
        "\n",
        "\n",
        "  cif_files = list(cif_dir.glob(\"*\"))\n",
        "  query_seq = SeqRecord(Seq(query_sequence),id=\"query\",name=\"\",description=\"\")\n",
        "  query_seq_path = Path(fasta_dir,\"query.fasta\")\n",
        "  with query_seq_path.open(\"w\") as fh:\n",
        "      SeqIO.write([query_seq], fh, \"fasta\")\n",
        "\n",
        "  shutil.copyfile(query_seq_path,Path(msa_dir,\"query.fasta\"))\n",
        "  seqs = []\n",
        "  template_hit_list = []\n",
        "\n",
        "  print(\"\\nProcessing templates...\")\n",
        "  for i,filepath in enumerate(cif_files):\n",
        "    with filepath.open(\"r\") as fh:\n",
        "      filestr = fh.read()\n",
        "      mmcif_obj = mmcif_parsing.parse(file_id=filepath.stem,mmcif_string=filestr)\n",
        "      mmcif = mmcif_obj.mmcif_object\n",
        "\n",
        "      for chain_id,template_sequence in mmcif.chain_to_seqres.items():\n",
        "        template_sequence = mmcif.chain_to_seqres[chain_id]\n",
        "        seq_name = filepath.stem.upper()+\"_\"+chain_id\n",
        "        seq = SeqRecord(Seq(template_sequence),id=seq_name,name=\"\",description=\"\")\n",
        "        seqs.append(seq)\n",
        "\n",
        "        with  Path(fasta_dir,seq.id+\".fasta\").open(\"w\") as fh:\n",
        "          SeqIO.write([seq], fh, \"fasta\")\n",
        "\n",
        "        \"\"\"\n",
        "        At this stage, we have a template sequence.\n",
        "        and a query sequence. \n",
        "        There are two options to generate template features:\n",
        "          1. Write new code to manually generate template features\n",
        "          2. Get an hhr alignment string, and pass that\n",
        "            to the existing template featurizer. \n",
        "            \n",
        "        I chose the second, implemented in hh_process_seq()\n",
        "        \"\"\"\n",
        "\n",
        "        hit = hh_process_seq(query_seq,seq,hhDB_dir)\n",
        "        if hit is not None:\n",
        "          template_hit_list.append(hit)\n",
        "\n",
        "  #process hits into template features\n",
        "  template_hit_list = [replace(hit,**{\"index\":i+1}) for i,hit in enumerate(template_hit_list)]\n",
        "  template_features = {}\n",
        "  for template_feature_name in TEMPLATE_FEATURES:\n",
        "    template_features[template_feature_name] = []\n",
        "\n",
        "  for i,hit in enumerate(sorted(template_hit_list, key=lambda x: x.sum_probs, reverse=True)):\n",
        "    # modifications to alphafold/data/templates.py _process_single_hit\n",
        "    hit_pdb_code, hit_chain_id = _get_pdb_id_and_chain(hit)\n",
        "    mapping = _build_query_to_hit_index_mapping(\n",
        "    hit.query, hit.hit_sequence, hit.indices_hit, hit.indices_query,\n",
        "    query_sequence)\n",
        "    template_sequence = hit.hit_sequence.replace('-', '')\n",
        "\n",
        "    features, realign_warning = _extract_template_features(\n",
        "      mmcif_object=mmcif,\n",
        "      pdb_id=hit_pdb_code,\n",
        "      mapping=mapping,\n",
        "      template_sequence=template_sequence,\n",
        "      query_sequence=query_sequence,\n",
        "      template_chain_id=hit_chain_id,\n",
        "      kalign_binary_path=\"kalign\")\n",
        "    features['template_sum_probs'] = [hit.sum_probs]\n",
        "\n",
        "    single_hit_result = SingleHitResult(features=features, error=None, warning=None)\n",
        "    for k in template_features:\n",
        "      template_features[k].append(features[k])\n",
        "\n",
        "\n",
        "  for name in template_features:\n",
        "    template_features[name] = np.stack(\n",
        "        template_features[name], axis=0).astype(TEMPLATE_FEATURES[name])\n",
        "    \n",
        "    \n",
        "    \n",
        "  #overwrite template data\n",
        "  template_paths = cif_dir.as_posix()\n",
        "  template_hits = template_hit_list\n",
        "  print(\"\\nIncluding templates:\")\n",
        "  for hit in template_hit_list:\n",
        "    print(\"\\t\",hit.name.split()[0])\n",
        "  os.chdir(\"/content/\")\n",
        "\n",
        "  for key,value in template_features.items():\n",
        "    if np.all(value==0):\n",
        "      print(\"ERROR: Some template features are empty\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3ee1d667-a09b-4426-96ad-d571a7bda744\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3ee1d667-a09b-4426-96ad-d571a7bda744\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing templates...\n",
            "\n",
            "Including templates:\n",
            "\t 7LXX_H\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUYApPElB30u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "54fbe8db-f674-4b52-d625-cba84b18cd55"
      },
      "source": [
        "#@title Gather input features, predict structure\n",
        "from string import ascii_uppercase\n",
        "\n",
        "# collect model weights\n",
        "use_model = {}\n",
        "if \"model_params\" not in dir(): model_params = {}\n",
        "for model_name in [\"model_1\",\"model_2\",\"model_3\",\"model_4\",\"model_5\"][:num_models]:\n",
        "  use_model[model_name] = True\n",
        "  if model_name not in model_params:\n",
        "    model_params[model_name] = data.get_model_haiku_params(model_name=model_name+\"_ptm\", data_dir=\".\")\n",
        "    if model_name == \"model_1\":\n",
        "      model_config = config.model_config(model_name+\"_ptm\")\n",
        "      model_config.data.eval.num_ensemble = 1\n",
        "      model_runner_1 = model.RunModel(model_config, model_params[model_name])\n",
        "    if model_name == \"model_3\":\n",
        "      model_config = config.model_config(model_name+\"_ptm\")\n",
        "      model_config.data.eval.num_ensemble = 1\n",
        "      model_runner_3 = model.RunModel(model_config, model_params[model_name])\n",
        "\n",
        "if homooligomer == 1:\n",
        "  msas = [msa]\n",
        "  deletion_matrices = [deletion_matrix]\n",
        "else:\n",
        "  # make multiple copies of msa for each copy\n",
        "  # AAA------\n",
        "  # ---AAA---\n",
        "  # ------AAA\n",
        "  #\n",
        "  # note: if you concat the sequences (as below), it does NOT work\n",
        "  # AAAAAAAAA\n",
        "  msas = []\n",
        "  deletion_matrices = []\n",
        "  Ln = len(query_sequence)\n",
        "  for o in range(homooligomer):\n",
        "    L = Ln * o\n",
        "    R = Ln * (homooligomer-(o+1))\n",
        "    msas.append([\"-\"*L+seq+\"-\"*R for seq in msa])\n",
        "    deletion_matrices.append([[0]*L+mtx+[0]*R for mtx in deletion_matrix])\n",
        "\n",
        "# gather features\n",
        "feature_dict = {\n",
        "    **pipeline.make_sequence_features(sequence=query_sequence*homooligomer,\n",
        "                                      description=\"none\",\n",
        "                                      num_res=len(query_sequence)*homooligomer),\n",
        "    **pipeline.make_msa_features(msas=msas,deletion_matrices=deletion_matrices),\n",
        "    **template_features\n",
        "}\n",
        "outs = predict_structure(jobname, feature_dict,\n",
        "                         Ls=[len(query_sequence)]*homooligomer,\n",
        "                         model_params=model_params, use_model=use_model,\n",
        "                         do_relax=use_amber)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running model_1\n",
            "running model_2\n",
            "running model_3\n",
            "running model_4\n",
            "running model_5\n",
            "reranking models based on avg. predicted lDDT\n",
            "model_1 96.78102640654376\n",
            "model_2 96.62027751903045\n",
            "model_3 93.02879251267596\n",
            "model_4 92.55305876513862\n",
            "model_5 91.88665396488939\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xbvRNrwnJqj",
        "cellView": "form"
      },
      "source": [
        "#@title Make plots\n",
        "\n",
        "# gather MSA info\n",
        "deduped_full_msa = list(dict.fromkeys(msa))\n",
        "msa_arr = np.array([list(seq) for seq in deduped_full_msa])\n",
        "seqid = (np.array(list(query_sequence)) == msa_arr).mean(-1)\n",
        "seqid_sort = seqid.argsort() #[::-1]\n",
        "non_gaps = (msa_arr != \"-\").astype(float)\n",
        "non_gaps[non_gaps == 0] = np.nan\n",
        "\n",
        "##################################################################\n",
        "plt.figure(figsize=(14,4),dpi=100)\n",
        "##################################################################\n",
        "plt.subplot(1,2,1); plt.title(\"Sequence coverage\")\n",
        "plt.imshow(non_gaps[seqid_sort]*seqid[seqid_sort,None],\n",
        "           interpolation='nearest', aspect='auto',\n",
        "           cmap=\"rainbow_r\", vmin=0, vmax=1, origin='lower')\n",
        "plt.plot((msa_arr != \"-\").sum(0), color='black')\n",
        "plt.xlim(-0.5,msa_arr.shape[1]-0.5)\n",
        "plt.ylim(-0.5,msa_arr.shape[0]-0.5)\n",
        "plt.colorbar(label=\"Sequence identity to query\",)\n",
        "plt.xlabel(\"Positions\")\n",
        "plt.ylabel(\"Sequences\")\n",
        "\n",
        "##################################################################\n",
        "plt.subplot(1,2,2); plt.title(\"Predicted lDDT per position\")\n",
        "for model_name,value in outs.items():\n",
        "  plt.plot(value[\"plddt\"],label=model_name)\n",
        "if homooligomer > 0:\n",
        "  for n in range(homooligomer+1):\n",
        "    x = n*(len(query_sequence)-1)\n",
        "    plt.plot([x,x],[0,100],color=\"black\")\n",
        "plt.legend()\n",
        "plt.ylim(0,100)\n",
        "plt.ylabel(\"Predicted lDDT\")\n",
        "plt.xlabel(\"Positions\")\n",
        "plt.savefig(jobname+\"_coverage_lDDT.png\")\n",
        "##################################################################\n",
        "plt.show()\n",
        "\n",
        "print(\"Predicted Alignment Error\")\n",
        "##################################################################\n",
        "plt.figure(figsize=(3*num_models,2), dpi=100)\n",
        "for n,(model_name,value) in enumerate(outs.items()):\n",
        "  plt.subplot(1,num_models,n+1)\n",
        "  plt.title(model_name)\n",
        "  plt.imshow(value[\"pae\"],label=model_name,cmap=\"bwr\",vmin=0,vmax=30)\n",
        "  plt.colorbar()\n",
        "plt.savefig(jobname+\"_PAE.png\")\n",
        "plt.show()\n",
        "##################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "KK7X9T44pWb7"
      },
      "source": [
        "#@title Display 3D structure {run: \"auto\"}\n",
        "model_num = 1 #@param [\"1\", \"2\", \"3\", \"4\", \"5\"] {type:\"raw\"}\n",
        "color = \"lDDT\" #@param [\"chain\", \"lDDT\", \"rainbow\"]\n",
        "show_sidechains = False #@param {type:\"boolean\"}\n",
        "show_mainchains = False #@param {type:\"boolean\"}\n",
        "\n",
        "def plot_plddt_legend():\n",
        "  thresh = ['plDDT:','Very low (<50)','Low (60)','OK (70)','Confident (80)','Very high (>90)']\n",
        "  plt.figure(figsize=(1,0.1),dpi=100)\n",
        "  ########################################\n",
        "  for c in [\"#FFFFFF\",\"#FF0000\",\"#FFFF00\",\"#00FF00\",\"#00FFFF\",\"#0000FF\"]:\n",
        "    plt.bar(0, 0, color=c)\n",
        "  plt.legend(thresh, frameon=False,\n",
        "             loc='center', ncol=6,\n",
        "             handletextpad=1,\n",
        "             columnspacing=1,\n",
        "             markerscale=0.5,)\n",
        "  plt.axis(False)\n",
        "  return plt\n",
        "\n",
        "def plot_confidence(model_num=1):\n",
        "  model_name = f\"model_{model_num}\"\n",
        "  plt.figure(figsize=(10,3),dpi=100)\n",
        "  \"\"\"Plots the legend for plDDT.\"\"\"\n",
        "  #########################################\n",
        "  plt.subplot(1,2,1); plt.title('Predicted lDDT')\n",
        "  plt.plot(outs[model_name][\"plddt\"])\n",
        "  for n in range(homooligomer+1):\n",
        "    x = n*(len(query_sequence))\n",
        "    plt.plot([x,x],[0,100],color=\"black\")\n",
        "  plt.ylabel('plDDT')\n",
        "  plt.xlabel('position')\n",
        "  #########################################\n",
        "  plt.subplot(1,2,2);plt.title('Predicted Aligned Error')\n",
        "  plt.imshow(outs[model_name][\"pae\"], cmap=\"bwr\",vmin=0,vmax=30)\n",
        "  plt.colorbar()\n",
        "  plt.xlabel('Scored residue')\n",
        "  plt.ylabel('Aligned residue')\n",
        "  #########################################\n",
        "  return plt\n",
        "\n",
        "def show_pdb(model_num=1, show_sidechains=False, show_mainchains=False, color=\"lDDT\"):\n",
        "  model_name = f\"model_{model_num}\"\n",
        "  if use_amber:\n",
        "    pdb_filename = f\"{jobname}_relaxed_{model_name}.pdb\"\n",
        "  else:\n",
        "    pdb_filename = f\"{jobname}_unrelaxed_{model_name}.pdb\"\n",
        "\n",
        "  view = py3Dmol.view(js='https://3dmol.org/build/3Dmol.js',)\n",
        "  view.addModel(open(pdb_filename,'r').read(),'pdb')\n",
        "\n",
        "  if color == \"lDDT\":\n",
        "    view.setStyle({'cartoon': {'colorscheme': {'prop':'b','gradient': 'roygb','min':50,'max':90}}})\n",
        "  elif color == \"rainbow\":\n",
        "    view.setStyle({'cartoon': {'color':'spectrum'}})\n",
        "  elif color == \"chain\":\n",
        "    for n,chain,color in zip(range(homooligomer),list(\"ABCDEFGH\"),\n",
        "                     [\"lime\",\"cyan\",\"magenta\",\"yellow\",\"salmon\",\"white\",\"blue\",\"orange\"]):\n",
        "       view.setStyle({'chain':chain},{'cartoon': {'color':color}})\n",
        "  if show_sidechains:\n",
        "    BB = ['C','O','N']\n",
        "    view.addStyle({'and':[{'resn':[\"GLY\",\"PRO\"],'invert':True},{'atom':BB,'invert':True}]},\n",
        "                        {'stick':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
        "    view.addStyle({'and':[{'resn':\"GLY\"},{'atom':'CA'}]},\n",
        "                        {'sphere':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
        "    view.addStyle({'and':[{'resn':\"PRO\"},{'atom':['C','O'],'invert':True}]},\n",
        "                        {'stick':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})  \n",
        "  if show_mainchains:\n",
        "    BB = ['C','O','N','CA']\n",
        "    view.addStyle({'atom':BB},{'stick':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
        "\n",
        "  view.zoomTo()\n",
        "  return view\n",
        "\n",
        "show_pdb(model_num,show_sidechains, show_mainchains, color).show()\n",
        "if color == \"lDDT\": plot_plddt_legend().show()  \n",
        "plot_confidence(model_num).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33g5IIegij5R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "cellView": "form",
        "outputId": "505e9243-bd77-43dc-e03e-4a8921aa1399"
      },
      "source": [
        "#@title Package and download results\n",
        "#@markdown If you are having issues downloading the result archive, try disabling your adblocker and run this cell again. If that fails click on the little folder icon to the left, navigate to file: `jobname.result.zip`, right-click and select \\\"Download\\\" (see [screenshot](https://pbs.twimg.com/media/E6wRW2lWUAEOuoe?format=jpg&name=small)).\n",
        "\n",
        "citations = {\n",
        "\"Mirdita2021\":  \"\"\"@article{Mirdita2021,\n",
        "author = {Mirdita, Milot and Ovchinnikov, Sergey and Steinegger, Martin},\n",
        "doi = {10.1101/2021.08.15.456425},\n",
        "journal = {bioRxiv},\n",
        "title = {{ColabFold - Making Protein folding accessible to all}},\n",
        "year = {2021},\n",
        "comment = {ColabFold including MMseqs2 MSA server}\n",
        "}\"\"\",\n",
        "  \"Mitchell2019\": \"\"\"@article{Mitchell2019,\n",
        "author = {Mitchell, Alex L and Almeida, Alexandre and Beracochea, Martin and Boland, Miguel and Burgin, Josephine and Cochrane, Guy and Crusoe, Michael R and Kale, Varsha and Potter, Simon C and Richardson, Lorna J and Sakharova, Ekaterina and Scheremetjew, Maxim and Korobeynikov, Anton and Shlemov, Alex and Kunyavskaya, Olga and Lapidus, Alla and Finn, Robert D},\n",
        "doi = {10.1093/nar/gkz1035},\n",
        "journal = {Nucleic Acids Res.},\n",
        "title = {{MGnify: the microbiome analysis resource in 2020}},\n",
        "year = {2019},\n",
        "comment = {MGnify database}\n",
        "}\"\"\",\n",
        "  \"Eastman2017\": \"\"\"@article{Eastman2017,\n",
        "author = {Eastman, Peter and Swails, Jason and Chodera, John D. and McGibbon, Robert T. and Zhao, Yutong and Beauchamp, Kyle A. and Wang, Lee-Ping and Simmonett, Andrew C. and Harrigan, Matthew P. and Stern, Chaya D. and Wiewiora, Rafal P. and Brooks, Bernard R. and Pande, Vijay S.},\n",
        "doi = {10.1371/journal.pcbi.1005659},\n",
        "journal = {PLOS Comput. Biol.},\n",
        "number = {7},\n",
        "title = {{OpenMM 7: Rapid development of high performance algorithms for molecular dynamics}},\n",
        "volume = {13},\n",
        "year = {2017},\n",
        "comment = {Amber relaxation}\n",
        "}\"\"\",\n",
        "  \"Jumper2021\": \"\"\"@article{Jumper2021,\n",
        "author = {Jumper, John and Evans, Richard and Pritzel, Alexander and Green, Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool, Kathryn and Bates, Russ and {\\v{Z}}{\\'{i}}dek, Augustin and Potapenko, Anna and Bridgland, Alex and Meyer, Clemens and Kohl, Simon A. A. and Ballard, Andrew J. and Cowie, Andrew and Romera-Paredes, Bernardino and Nikolov, Stanislav and Jain, Rishub and Adler, Jonas and Back, Trevor and Petersen, Stig and Reiman, David and Clancy, Ellen and Zielinski, Michal and Steinegger, Martin and Pacholska, Michalina and Berghammer, Tamas and Bodenstein, Sebastian and Silver, David and Vinyals, Oriol and Senior, Andrew W. and Kavukcuoglu, Koray and Kohli, Pushmeet and Hassabis, Demis},\n",
        "doi = {10.1038/s41586-021-03819-2},\n",
        "journal = {Nature},\n",
        "pmid = {34265844},\n",
        "title = {{Highly accurate protein structure prediction with AlphaFold.}},\n",
        "year = {2021},\n",
        "comment = {AlphaFold2 + BFD Database}\n",
        "}\"\"\",\n",
        "  \"Mirdita2019\": \"\"\"@article{Mirdita2019,\n",
        "author = {Mirdita, Milot and Steinegger, Martin and S{\\\"{o}}ding, Johannes},\n",
        "doi = {10.1093/bioinformatics/bty1057},\n",
        "journal = {Bioinformatics},\n",
        "number = {16},\n",
        "pages = {2856--2858},\n",
        "pmid = {30615063},\n",
        "title = {{MMseqs2 desktop and local web server app for fast, interactive sequence searches}},\n",
        "volume = {35},\n",
        "year = {2019},\n",
        "comment = {MMseqs2 search server}\n",
        "}\"\"\",\n",
        "  \"Steinegger2019\": \"\"\"@article{Steinegger2019,\n",
        "author = {Steinegger, Martin and Meier, Markus and Mirdita, Milot and V{\\\"{o}}hringer, Harald and Haunsberger, Stephan J. and S{\\\"{o}}ding, Johannes},\n",
        "doi = {10.1186/s12859-019-3019-7},\n",
        "journal = {BMC Bioinform.},\n",
        "number = {1},\n",
        "pages = {473},\n",
        "pmid = {31521110},\n",
        "title = {{HH-suite3 for fast remote homology detection and deep protein annotation}},\n",
        "volume = {20},\n",
        "year = {2019},\n",
        "comment = {PDB70 database}\n",
        "}\"\"\",\n",
        "  \"Mirdita2017\": \"\"\"@article{Mirdita2017,\n",
        "author = {Mirdita, Milot and von den Driesch, Lars and Galiez, Clovis and Martin, Maria J. and S{\\\"{o}}ding, Johannes and Steinegger, Martin},\n",
        "doi = {10.1093/nar/gkw1081},\n",
        "journal = {Nucleic Acids Res.},\n",
        "number = {D1},\n",
        "pages = {D170--D176},\n",
        "pmid = {27899574},\n",
        "title = {{Uniclust databases of clustered and deeply annotated protein sequences and alignments}},\n",
        "volume = {45},\n",
        "year = {2017},\n",
        "comment = {Uniclust30/UniRef30 database},\n",
        "}\"\"\",\n",
        "  \"Berman2003\": \"\"\"@misc{Berman2003,\n",
        "author = {Berman, Helen and Henrick, Kim and Nakamura, Haruki},\n",
        "booktitle = {Nat. Struct. Biol.},\n",
        "doi = {10.1038/nsb1203-980},\n",
        "number = {12},\n",
        "pages = {980},\n",
        "pmid = {14634627},\n",
        "title = {{Announcing the worldwide Protein Data Bank}},\n",
        "volume = {10},\n",
        "year = {2003},\n",
        "comment = {templates downloaded from wwPDB server}\n",
        "}\"\"\",\n",
        "}\n",
        "\n",
        "to_cite = [ \"Mirdita2021\", \"Jumper2021\" ]\n",
        "if use_msa:       to_cite += [\"Mirdita2019\"]\n",
        "if use_msa:       to_cite += [\"Mirdita2017\"]\n",
        "if use_env:       to_cite += [\"Mitchell2019\"]\n",
        "if use_templates: to_cite += [\"Steinegger2019\"]\n",
        "if use_templates: to_cite += [\"Berman2003\"]\n",
        "if use_amber:     to_cite += [\"Eastman2017\"]\n",
        "\n",
        "with open(f\"{jobname}.bibtex\", 'w') as writer:\n",
        "  for i in to_cite:\n",
        "    writer.write(citations[i])\n",
        "    writer.write(\"\\n\")\n",
        "\n",
        "print(f\"Found {len(to_cite)} citation{'s' if len(to_cite) > 1 else ''} for tools or databases.\")\n",
        "if use_custom_msa:\n",
        "  print(\"Don't forget to cite your custom MSA generation method.\")\n",
        "\n",
        "!zip -FSr $jobname\".result.zip\" $jobname\".log\" $a3m_file $jobname\"_\"*\"relaxed_model_\"*\".pdb\" $jobname\"_coverage_lDDT.png\" $jobname\".bibtex\" $jobname\"_PAE.png\"\n",
        "files.download(f\"{jobname}.result.zip\")\n",
        "\n",
        "if save_to_google_drive == True and drive != None:\n",
        "  uploaded = drive.CreateFile({'title': f\"{jobname}.result.zip\"})\n",
        "  uploaded.SetContentFile(f\"{jobname}.result.zip\")\n",
        "  uploaded.Upload()\n",
        "  print(f\"Uploaded {jobname}.result.zip to Google Drive with ID {uploaded.get('id')}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7 citations for tools or databases.\n",
            "\tzip warning: name not matched: manual_template_45662_coverage_lDDT.png\n",
            "\tzip warning: name not matched: manual_template_45662_PAE.png\n",
            "  adding: manual_template_45662.log (deflated 13%)\n",
            "  adding: manual_template_45662.a3m (deflated 67%)\n",
            "  adding: manual_template_45662_unrelaxed_model_1.pdb (deflated 78%)\n",
            "  adding: manual_template_45662_unrelaxed_model_2.pdb (deflated 78%)\n",
            "  adding: manual_template_45662_unrelaxed_model_3.pdb (deflated 78%)\n",
            "  adding: manual_template_45662_unrelaxed_model_4.pdb (deflated 78%)\n",
            "  adding: manual_template_45662_unrelaxed_model_5.pdb (deflated 78%)\n",
            "  adding: manual_template_45662.bibtex (deflated 55%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_1d4df49c-ae77-4785-aa7d-439327390687\", \"manual_template_45662.result.zip\", 826120)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "fq2HJBe6vdBU",
        "outputId": "4d1b4ff8-fe11-4266-b7af-553f28d001cc"
      },
      "source": [
        "#@markdown ---\n",
        "#@markdown #### Optional: Package and download any templates used\n",
        "from alphafold.data.templates import _get_pdb_id_and_chain\n",
        "from pathlib import Path\n",
        "\n",
        "if not use_templates:\n",
        "  print(\"No templates used\")\n",
        "else:\n",
        "  cif_files = [f for f in Path(template_paths).glob(\"*\") if f.suffix in [\".cif\",\".mmcif\"]]\n",
        "  cif_files_used = []\n",
        "  for hit in template_hits:\n",
        "    code,chain_id = _get_pdb_id_and_chain(hit)\n",
        "    for f in cif_files:\n",
        "      if code in f.name or code.upper() in f.name:\n",
        "        cif_files_used.append(f)\n",
        "\n",
        "\n",
        "  zip_string = \" \".join([cif_file.as_posix() for cif_file in cif_files_used])\n",
        "\n",
        "  !zip -FSrj $jobname\".templates.zip\" $zip_string\n",
        "  files.download(f\"{jobname}.templates.zip\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No templates used\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGUBLzB3C6WN"
      },
      "source": [
        "# Instructions <a name=\"Instructions\"></a>\n",
        "**Quick start**\n",
        "1. Paste your protein sequence in the input field.\n",
        "2. Press \"Runtime\" -> \"Run all\".\n",
        "3. The pipeline consists of 8 steps. The currently running steps is indicated by a circle with a stop sign next to it.\n",
        "\n",
        "**Result zip file contents**\n",
        "\n",
        "1. PDB formatted structures sorted by avg. pIDDT. (unrelaxed and relaxed if `use_amber` is enabled).\n",
        "2. Plots of the model quality.\n",
        "3. Plots of the MSA coverage.\n",
        "4. Parameter log file.\n",
        "5. A3M formatted input MSA.\n",
        "6. BibTeX file with citations for all used tools and databases.\n",
        "\n",
        "At the end of the job a download modal box will pop up with a `jobname.result.zip` file. Additionally, if the `save_to_google_drive` option was selected, the `jobname.result.zip` will be uploaded to your Google Drive.\n",
        "\n",
        "**Using a custom MSA as input**\n",
        "\n",
        "To predict the structure with a custom MSA (A3M formatted): (1) Change the msa_mode: to \"custom\", (2) Wait for an upload box to appear at the end of the \"Input Protein ...\" box. Upload your A3M. The first fasta entry of the A3M must be the query sequence without gaps.\n",
        "\n",
        "As an alternative for MSA generation the [HHblits Toolkit server](https://toolkit.tuebingen.mpg.de/tools/hhblits) can be used. After submitting your query, click \"Query Template MSA\" -> \"Download Full A3M\". Download the A3M file and upload it in this notebook.\n",
        "\n",
        "**Troubleshooting**\n",
        "* Check that the runtime type is set to GPU at \"Runtime\" -> \"Change runtime type\".\n",
        "* Try to restart the session \"Runtime\" -> \"Factory reset runtime\".\n",
        "* Check your input sequence.\n",
        "\n",
        "**Known issues**\n",
        "* Google Colab assigns different types of GPUs with varying amount of memory. Some might not have enough memory to predict the structure for a long sequence.\n",
        "* Your browser can block the pop-up for downloading the result file. You can choose the `save_to_google_drive` option to upload to Google Drive instead or manually download the result file: Click on the little folder icon to the left, navigate to file: `jobname.result.zip`, right-click and select \\\"Download\\\" (see [screenshot](https://pbs.twimg.com/media/E6wRW2lWUAEOuoe?format=jpg&name=small)).\n",
        "\n",
        "**Limitations**\n",
        "* Computing resources: Our MMseqs2 API can handle ~20-50k requests per day.\n",
        "* MSAs: MMseqs2 is very precise and sensitive but might find less hits compared to HHblits/HMMer searched against BFD or Mgnify.\n",
        "* We recommend to additionally use the full [AlphaFold2 pipeline](https://github.com/deepmind/alphafold).\n",
        "\n",
        "**Description of the plots**\n",
        "*   **Number of sequences per position** - We want to see at least 30 sequences per position, for best performance, ideally 100 sequences.\n",
        "*   **Predicted lDDT per position** - model confidence (out of 100) at each position. The higher the better.\n",
        "*   **Predicted Alignment Error** - For homooligomers, this could be a useful metric to assess how confident the model is about the interface. The lower the better.\n",
        "\n",
        "**Bugs**\n",
        "- If you encounter any bugs, please report the issue to https://github.com/sokrypton/ColabFold/issues\n",
        "\n",
        "\n",
        "**Acknowledgments**\n",
        "- We thank the AlphaFold team for developing an excellent model and open sourcing the software. \n",
        "\n",
        "- [Söding Lab](https://www.mpibpc.mpg.de/soeding) for providing the computational resources for the MMseqs2 server\n",
        "\n",
        "- Minkyung Baek ([@minkbaek](https://twitter.com/minkbaek)) and Yoshitaka Moriwaki ([@Ag_smith](https://twitter.com/Ag_smith)) for protein-complex prediction proof-of-concept in AlphaFold2.\n",
        "\n",
        "- [David Koes](https://github.com/dkoes) for his awesome [py3Dmol](https://3dmol.csb.pitt.edu/) plugin, without whom these notebooks would be quite boring!\n",
        "\n",
        "- Do-Yoon Kim for creating the ColabFold logo.\n",
        "\n",
        "- A colab by Sergey Ovchinnikov ([@sokrypton](https://twitter.com/sokrypton)), Milot Mirdita ([@milot_mirdita](https://twitter.com/milot_mirdita)) and Martin Steinegger ([@thesteinegger](https://twitter.com/thesteinegger)).\n"
      ]
    }
  ]
}